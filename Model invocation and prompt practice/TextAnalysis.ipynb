{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778d0b4-ea9a-4706-8f68-19939302f389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Creating a Table of Product Descriptions\n",
    "\n",
    "\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "\n",
    "modelId = 'amazon.titan-text-lite-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Product: Sunglasses. \n",
    "Keywords: polarized, designer, comfortable, UV protection, aviators. \n",
    "\n",
    "Create a table that contains five variations of a detailed product description for the product listed above, each variation of the product description must use all the keywords listed.\n",
    "\"\"\"\n",
    "input = {\n",
    "        'inputText': prompt,\n",
    "        'textGenerationConfig': {\n",
    "              'maxTokenCount': 4096,\n",
    "              'stopSequences': [],\n",
    "              'temperature': 0,\n",
    "              'topP': 1\n",
    "        }\n",
    "    }\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "results = response_body['results']\n",
    "for result in results:\n",
    "    print(result['outputText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b5717c-0309-459c-a38b-1dcc5df8362a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action items for Brant:\n",
      "1. Work with James from another team to unblock the sign up workflow. \n",
      "2. Work on the additional forms. \n",
      "\n",
      "Action items for Miguel:\n",
      "1. Document any other concerns. \n",
      "2. Discuss with James only once.\n"
     ]
    }
   ],
   "source": [
    "modelId = 'amazon.titan-text-lite-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Meeting transcript: \n",
    "Miguel: Hi Brant, I want to discuss the workstream  for our new product launch \n",
    "Brant: Sure Miguel, is there anything in particular you want to discuss? \n",
    "Miguel: Yes, I want to talk about how users enter into the product. \n",
    "Brant: Ok, in that case let me add in Namita. \n",
    "Namita: Hey everyone \n",
    "Brant: Hi Namita, Miguel wants to discuss how users enter into the product. \n",
    "Miguel: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms?  I also find it difficult to find where to access the product when I first land on the landing page. \n",
    "Brant: I would also add that I think there are too many steps. \n",
    "Namita: Ok, I can work on the landing page to make the product more discoverable but brant can you work on the additonal forms? \n",
    "Brant: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow.  Miguel can you document any other concerns so that I can discuss with James only once? \n",
    "Miguel: Sure. \n",
    "From the meeting transcript above, Create a list of action items for each person. \n",
    "\"\"\"\n",
    "input = {\n",
    "        'inputText': prompt,\n",
    "        'textGenerationConfig': {\n",
    "              'maxTokenCount': 4096,\n",
    "              'stopSequences': [],\n",
    "              'temperature': 0,\n",
    "              'topP': 1\n",
    "        }\n",
    "    }\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "results = response_body['results']\n",
    "for result in results:\n",
    "    print(result['outputText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed768c7-d2cf-4e26-a97a-1b7b032131f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{“Cleaning”: “Positive”, “Pool”: “Negative”, “WiFi”: “Negative”, “Location”: “Positive”}\n",
      "The sentiment analysis of the reviews is as follows:\n",
      "\n",
      "* Review 1:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract Topics and Sentiments from Reviews\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'ai21.j2-ultra'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Review: \n",
    "Extremely old cabinets, phone was half broken and full of dust. Bathroom door was broken, bathroom floor was dirty and yellow. Bathroom tiles were falling off. Asked to change my room and the next room was in the same conditions. The most out of date and least maintained hotel i ever been on.\n",
    "Extracted sentiment:\n",
    "{“Cleaning”: “Negative”, “Hotel Facilities”: “Negative”, “Room Quality”: “Negative”}\n",
    "## \n",
    "Review: \n",
    "Great experience for two teenagers. We would book again. Location good. \n",
    "Extracted sentiment:\n",
    "{“Location”: “Positive”}\n",
    "## \n",
    "Review: \n",
    "Pool area was definitely a little run down and did not look like the pics online at all. Bathroom in the double room was kind of dumpy.\n",
    "Extracted sentiment:\n",
    "{“Pool”: “Negative”, “Room Quality”: “Negative”}\n",
    "## \n",
    "Review: \n",
    "Roof top’s view is gorgeous and the lounge area is comfortable. The staff is very courteous and the location is great. The hotel is outdated and the shower need to be clean better. The air condition runs all the time and cannot be control by the temperature control setting. \n",
    "Extracted sentiment:\n",
    "{“Cleaning”: “Negative”, “AC”: “Negative”, “Room Quality”: “Negative”, “Service”: “Positive”, “View”: “Positive”, “Hotel Facilities”: “Positive”}\n",
    "## \n",
    "Review: \n",
    "First I was placed near the elevator where it was noises, the TV is not updated, the toilet was coming on and off. There was no temp control and my shower curtain smelled moldy. Not sure what happened to this place but only thing was a great location.\n",
    "Extracted sentiment:\n",
    "{“Cleaning”: “Negative”, “AC”: “Negative”, “Room Quality”: “Negative”, “Location”: “Positive”}\n",
    "## \n",
    "Review: \n",
    "This is a very well located hotel and it’s nice and clean. Would stay here again. \n",
    "Extracted sentiment:\n",
    "{“Cleaning”: “Positive”, “Location”: “Positive”}\n",
    "## \n",
    "Review: \n",
    "Hotel is horrendous. The room was dark and dirty. No toilet paper in the bathroom. Came here on a work trip and had zero access to WiFi even though their hotel claims to have WiFi service. I will NEVER return.\n",
    "Extracted sentiment:\n",
    "{“Cleaning”: “Negative”, “WiFi”: “Negative”, “Room Quality”: “Negative”, “Service”: “Negative”}\n",
    "## \n",
    "Review: \n",
    "The rooms are small but clean and comfortable. The front desk was really busy and the lines for check-in were very long but the staff handled each person in a professional and very pleasant way. We will stay there again. \n",
    "Extracted sentiment:\n",
    "{“Cleaning”: “Positive”, “Service”: “Positive”}\n",
    "## \n",
    "Review: \n",
    "The stay was very nice would stay again. The pool closes at 7 pm and doesn’t open till 11am m. That sucked. Also our wifi went out the entire last day we were there. Thats sucked too. Overall was a nice enough stay and I love the location.\n",
    "Extracted sentiment:\n",
    "\"\"\"\n",
    "input = {\n",
    "    'prompt': prompt, \n",
    "    'maxTokens': 50,\n",
    "    'temperature': 0,\n",
    "    'topP': 0.5,\n",
    "    'stopSequences': [],\n",
    "    'countPenalty': {'scale': 0},\n",
    "    'presencePenalty': {'scale': 0},\n",
    "    'frequencyPenalty': {'scale': 0}\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "completions = response_body['completions']\n",
    "for part in completions:\n",
    "    print(part['data']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1ab985-b889-4647-be59-3b7875a33653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This t-shirt is perfect for anyone who wants to make a statement. The soft cotton and short sleeves make it comfortable to wear, and the print of Einstein's quote is sure to get people talking. Whether you're a fan of science or just want to show off your personality, this t-shirt is a great choice.\n"
     ]
    }
   ],
   "source": [
    "# Generate Product Descriptions\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'ai21.j2-ultra'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Write an engaging product description for a clothing eCommerce site. Make sure to include the following features in the description. \n",
    "Product: Humor Men's Graphic T-Shirt. \n",
    "Features: \n",
    "- Soft cotton \n",
    "- Short sleeve\n",
    "- Have a print of Einstein's quote: \"artificial intelligence is no match for natural stupidity” \n",
    "Description: \n",
    "\"\"\"\n",
    "input = {\n",
    "    'prompt': prompt, \n",
    "    'maxTokens': 100,\n",
    "    'temperature': 0.7,\n",
    "    'topP': 1.0,\n",
    "    'stopSequences': [],\n",
    "    'countPenalty': {'scale': 0},\n",
    "    'presencePenalty': {'scale': 0},\n",
    "    'frequencyPenalty': {'scale': 0}\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "completions = response_body['completions']\n",
    "for part in completions:\n",
    "    print(part['data']['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d221f5b9-8097-4ace-b20e-552fcd7d51d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john909709@geemail.com\n",
      "josie@josielananier.com\n",
      "drkevin22@geemail.com\n"
     ]
    }
   ],
   "source": [
    "# Information Extraction\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Please precisely copy any email addresses from the following text and then write them, one per line. Only write an email address if it's precisely spelled out in the input text. If there are no email addresses in the text, write \"N/A\". Do not say anything else. \n",
    "\n",
    "\"Phone Directory:\n",
    "John Latrabe, 800-232-1995, john909709@geemail.com\n",
    "Josie Lana, 800-759-2905, josie@josielananier.com\n",
    "Keven Stevens, 800-980-7000, drkevin22@geemail.com \n",
    "Phone directory will be kept up to date by the HR manager.\" \n",
    "\"\"\"\n",
    "user_message = {'role': 'user', 'content': prompt}\n",
    "messages = [user_message]\n",
    "input = {\n",
    "    'anthropic_version': 'bedrock-2023-05-31',\n",
    "    'max_tokens': 1024,\n",
    "    'system': '',\n",
    "    'messages': messages\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "content = response_body['content']\n",
    "for item in content:\n",
    "    print(item['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86c2727-1b68-4fe7-b068-78f548319c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This email would be categorized as (A) Pre-sale question.\n",
      "\n",
      "Explanation: The customer is inquiring about the intended usage of the Mixmaster 4000 before making a purchase decision. They want to know if it can be used for mixing paint or if it is solely meant for mixing food. This type of inquiry is typical of a pre-sale question, where potential buyers seek clarification or additional information about a product's features, capabilities, or intended use before making a purchase.\n"
     ]
    }
   ],
   "source": [
    "# Multiple Choice Classification\n",
    "\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "You are a customer service agent that is classifying emails by type. I want you to give your answer and then explain it. \n",
    "How would you categorize this email? \n",
    "\n",
    "<email>\n",
    "Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\n",
    "</email> \n",
    "\n",
    "Categories are: \n",
    "(A) Pre-sale question \n",
    "(B) Broken or defective item \n",
    "(C) Billing question \n",
    "(D) Other (please explain)\n",
    "\"\"\"\n",
    "user_message = {'role': 'user', 'content': prompt}\n",
    "messages = [user_message]\n",
    "input = {\n",
    "    'anthropic_version': 'bedrock-2023-05-31',\n",
    "    'max_tokens': 1024,\n",
    "    'system': '',\n",
    "    'messages': messages\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "content = response_body['content']\n",
    "for item in content:\n",
    "    print(item['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5fffb67-5c89-4af4-823d-5835ade86620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Introduction\n",
      "2. What is prompt engineering?\n",
      "3. The importance of prompt engineering\n",
      "4. My experience with prompt engineering\n",
      "5. Conclusion\n"
     ]
    }
   ],
   "source": [
    "# Outline Generation\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'ai21.j2-ultra'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Suggest an outline for a blog post based on a title. \n",
    "Title: How I put the pro in prompt engineering \n",
    "\"\"\"\n",
    "input = {\n",
    "    'prompt': prompt, \n",
    "    'maxTokens': 300,\n",
    "    'temperature': 0.7,\n",
    "    'topP': 0.95,\n",
    "    'stopSequences': [],\n",
    "    'countPenalty': {'scale': 0},\n",
    "    'presencePenalty': {'scale': 0},\n",
    "    'frequencyPenalty': {'scale': 0}\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "completions = response_body['completions']\n",
    "for part in completions:\n",
    "    print(part['data']['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5463dcc8-8def-425e-84f2-b3b389357211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "# Question and Answer\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Have you heard of the following company? \n",
    "\"Anthropic\" \n",
    "Please reply with Yes or No. Do not say anything else.\n",
    "\"\"\"\n",
    "user_message = {'role': 'user', 'content': prompt}\n",
    "messages = [user_message]\n",
    "input = {\n",
    "    'anthropic_version': 'bedrock-2023-05-31',\n",
    "    'max_tokens': 1024,\n",
    "    'system': '',\n",
    "    'messages': messages\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "content = response_body['content']\n",
    "for item in content:\n",
    "    print(item['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c5014a-c8ca-4576-8b26-ffd8a752f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>\n",
      "   XXX: Hi XXX!\n",
      "   XXX: Hi XXX! Are you coming over?  \n",
      "   XXX: Yup! Hey I, uh, forgot where you live.\n",
      "   XXX: No problem! It's XXX XXX, XXX XXX XXXXX.\n",
      "   XXX: Got it, thanks!  \n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "# Remove PII\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "Here is some text. We want to remove all personally identifying information from this text and replace it with XXX. It's very important that names, phone numbers, and email addresses, gets replaced with XXX. \n",
    "Here is the text, inside <text></text> XML tags\n",
    "<text>\n",
    "   Joe: Hi Hannah!\n",
    "   Hannah: Hi Joe! Are you coming over?  \n",
    "   Joe: Yup! Hey I, uh, forgot where you live.\" \n",
    "   Hannah: No problem! It's 4085 Paco Ln, Los Altos CA 94306.\n",
    "   Joe: Got it, thanks!  \n",
    "</text> \n",
    "Please put your sanitized version of the text with PII removed in <response></response> XML tags.\n",
    "\"\"\"\n",
    "user_message = {'role': 'user', 'content': prompt}\n",
    "messages = [user_message]\n",
    "input = {\n",
    "    'anthropic_version': 'bedrock-2023-05-31',\n",
    "    'max_tokens': 1024,\n",
    "    'system': '',\n",
    "    'messages': messages\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "content = response_body['content']\n",
    "for item in content:\n",
    "    print(item['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631baf59-5a38-4bfe-ac39-b2a3e9777406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Generative AI applications like ChatGPT are capturing attention and imagination.\n",
      "\n",
      "2. Amazon has been focused on AI and ML for over 20 years and has thousands of engineers working on these technologies.\n",
      "\n",
      "3. AWS is democratizing ML and making it accessible to all customers, with a broad portfolio of AI and ML services and the easiest way for developers to build, train, and deploy models.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the Key Takeaways\n",
    "\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "\n",
    "modelId = 'meta.llama2-13b-chat-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "The seeds of a machine learning (ML) paradigm shift have existed for decades, but with the ready availability of scalable compute capacity, a massive proliferation of data, and the rapid advancement of ML technologies, customers across industries are transforming their businesses. Just recently, generative AI applications like ChatGPT have captured widespread attention and imagination. We are truly at an exciting inflection point in the widespread adoption of ML, and we believe most customer experiences and applications will be reinvented with generative AI. AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. Our e-commerce recommendations engine is driven by ML; the paths that optimize robotic picking routes in our fulfillment centers are driven by ML; and our supply chain, forecasting, and capacity planning are informed by ML. Prime Air (our drones) and the computer vision technology in Amazon Go (our physical retail experience that lets consumers select items off a shelf and leave the store without having to formally check out) use deep learning. Alexa, powered by more than 30 different ML systems, helps customers billions of times each week to manage smart homes, shop, get information and entertainment, and more. We have thousands of engineers at Amazon committed to ML, and it’s a big part of our heritage, current ethos, and future. At AWS, we have played a key role in democratizing ML and making it accessible to anyone who wants to use it, including more than 100,000 customers of all sizes and industries. AWS has the broadest and deepest portfolio of AI and ML services at all three layers of the stack. We’ve invested and innovated to offer the most performant, scalable infrastructure for cost-effective ML training and inference; developed Amazon SageMaker, which is the easiest way for all developers to build, train, and deploy models; and launched a wide range of services that allow customers to add AI capabilities like image recognition, forecasting, and intelligent search to applications with a simple API call. This is why customers like Intuit, Thomson Reuters, AstraZeneca, Ferrari, Bundesliga, 3M, and BMW, as well as thousands of startups and government agencies around the world, are transforming themselves, their industries, and their missions with ML. We take the same democratizing approach to generative AI: we work to take these technologies out of the realm of research and experiments and extend their availability far beyond a handful of startups and large, well-funded tech companies. That’s why today I’m excited to announce several new innovations that will make it easy and practical for our customers to use generative AI in their businesses.\n",
    "\n",
    "Summarize the above text into three key takeaways. \n",
    "\"\"\"\n",
    "input = {\n",
    "    'prompt': prompt,\n",
    "    'max_gen_len': 512,\n",
    "    'temperature': 0.5,\n",
    "    'top_p': 0.9\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "results = response_body['generation']\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98254a9e-4308-4b9c-b0d5-bf99cdaf0bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the translation into English:\n",
      "\n",
      "The white sun sets behind the mountains, the Yellow River flows into the sea.\n",
      "If you wish to gaze farther than a thousand miles, then ascend another story higher.\n",
      "\n",
      "This is a famous poem by Chinese poet Li Bai from the Tang Dynasty era. It evokes imagery of the vast landscape and expresses the idea that to gain a wider perspective, one must continue climbing to greater heights, both literally and metaphorically.\n"
     ]
    }
   ],
   "source": [
    "# Machine Translation\n",
    "\n",
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "prompt = \"\"\"\n",
    "I'd like you to translate this paragraph into English:\n",
    "\n",
    "白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\n",
    "\"\"\"\n",
    "user_message = {'role': 'user', 'content': prompt}\n",
    "messages = [user_message]\n",
    "input = {\n",
    "    'anthropic_version': 'bedrock-2023-05-31',\n",
    "    'max_tokens': 1024,\n",
    "    'system': '',\n",
    "    'messages': messages\n",
    "}\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "content = response_body['content']\n",
    "for item in content:\n",
    "    print(item['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8a142-9ce8-4f57-bf7b-e12dc714cbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
