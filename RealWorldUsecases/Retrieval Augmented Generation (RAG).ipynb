{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e3c3d-9612-4698-84fd-e02658b9a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With retrieval augmented generation, we use the following steps to generate context aware answers:\n",
    "\n",
    "#     Convert the prompt (question text) into embedding.\n",
    "#     (R) Retrieve N most relevant entries from the knowledge base. This is treated as the context of the conversation.\n",
    "#     (A) Augment the prompt with the context by prepending the context to the question text. This end result is the context aware prompt.\n",
    "#     (G)\" Generate the answer by feeding the context aware prompt to the foundation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e200c4-74ff-4a3a-8bfb-f8ec5ab13633",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-west-2'\n",
    "host = 'https://b19fa6b2rsx72rc9osh8.us-west-2.aoss.amazonaws.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe1f06a-bd4d-4d40-be93-6f2aba63989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Albert Einstein worked as a patent clerk shortly after his marriage to Mileva MariÄ‡. In 1909 he obtained a associate professorship at the University of Bern and in 1912 became an Professor of Theoretical Physics at the University of Zurich. Eventually Einstein moved to Berlin in 1914 where he became a member of the Prussian Academy of Sciences and a professor at the Humboldt University of Berlin. From onward Einstein was spends the rest of his his time working in theoretical physics from 1914 onwards.  This was where he had his most important discoveries which gave him his fame. In 1921, he was awarded the Nobel Prize in Physics \"for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect\". In the late 1920s, Einstein faced terrible trials of cancers of the economy which lead him to move to America in 1933 where be lectured at several universities. Throughout the rest of his life Einstein continued to work on physics and other various projects.\n",
      "\n",
      "Based on the context provided, Albert Einstein works as a support engineer in various cities.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "def get_embedding(bedrock, text):\n",
    "    modelId = 'amazon.titan-embed-text-v1'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    input = {\n",
    "            'inputText': text\n",
    "        }\n",
    "    body=json.dumps(input)\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept,contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body['embedding']\n",
    "    return embedding\n",
    "    \n",
    "def search(embedding, limit=1):\n",
    "    # prepare for OpenSearch Serverless\n",
    "    service = 'aoss'\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    awsauth = AWS4Auth(\n",
    "        credentials.access_key, \n",
    "        credentials.secret_key, \n",
    "        region, \n",
    "        service, \n",
    "        session_token=credentials.token\n",
    "    )\n",
    "    # search\n",
    "    index = 'demo-index'\n",
    "    datatype = '_search'\n",
    "    url = host + '/' + index + '/' + datatype\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    document = {\n",
    "        'size': limit,\n",
    "        'query': {\n",
    "            'knn': {\n",
    "                'embedding': {\n",
    "                    'vector': embedding,\n",
    "                    'k': limit\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # response\n",
    "    response = requests.get(url, auth=awsauth, json=document, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    output = ''\n",
    "    for item in data['hits']['hits']:\n",
    "        output += item['_source']['content'] + '\\n'\n",
    "    return output\n",
    "\n",
    "# main function\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "# this is the original prompt (query text)\n",
    "prompt = 'What does Albert Einstein do?'\n",
    "# convet the query text into embedding\n",
    "embedding = get_embedding(bedrock, prompt)\n",
    "# retrieve 5 most relevant entries from the knowledge base\n",
    "info = search(embedding, limit=5)\n",
    "# augment the prompt with the context\n",
    "RAGprompt = 'Use the context below to answer the question:\\n\\n=== Context ===\\n{0}\\n\\n=== Question ===\\n{1}'.format(info, prompt)\n",
    "# ask the foundation model\n",
    "modelId = 'ai21.j2-ultra'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "input = {'prompt': prompt, 'maxTokens': 200}\n",
    "input1 = {'prompt': RAGprompt, 'maxTokens': 200}\n",
    "body=json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept,contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "completions = response_body['completions']\n",
    "for part in completions:\n",
    "    print(part['data']['text'])\n",
    "\n",
    "body1=json.dumps(input1)\n",
    "response = bedrock.invoke_model(body=body1, modelId=modelId, accept=accept,contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "completions = response_body['completions']\n",
    "for part in completions:\n",
    "    print(part['data']['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae3348-ab14-47f4-910e-05322118a1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
