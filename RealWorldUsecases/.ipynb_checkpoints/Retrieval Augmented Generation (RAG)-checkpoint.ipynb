{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e3c3d-9612-4698-84fd-e02658b9a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With retrieval augmented generation, we use the following steps to generate context aware answers:\n",
    "\n",
    "#     Convert the prompt (question text) into embedding.\n",
    "#     (R) Retrieve N most relevant entries from the knowledge base. This is treated as the context of the conversation.\n",
    "#     (A) Augment the prompt with the context by prepending the context to the question text. This end result is the context aware prompt.\n",
    "#     (G)\" Generate the answer by feeding the context aware prompt to the foundation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e200c4-74ff-4a3a-8bfb-f8ec5ab13633",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-west-2'\n",
    "host = 'https://b19fa6b2rsx72rc9osh8.us-west-2.aoss.amazonaws.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe1f06a-bd4d-4d40-be93-6f2aba63989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "He is a support engineer\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "def get_embedding(bedrock, text):\n",
    "    modelId = 'amazon.titan-embed-text-v1'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    input = {\n",
    "            'inputText': text\n",
    "        }\n",
    "    body=json.dumps(input)\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept,contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body['embedding']\n",
    "    return embedding\n",
    "    \n",
    "def search(embedding, limit=1):\n",
    "    # prepare for OpenSearch Serverless\n",
    "    service = 'aoss'\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    awsauth = AWS4Auth(\n",
    "        credentials.access_key, \n",
    "        credentials.secret_key, \n",
    "        region, \n",
    "        service, \n",
    "        session_token=credentials.token\n",
    "    )\n",
    "    # search\n",
    "    index = 'demo-index'\n",
    "    datatype = '_search'\n",
    "    url = host + '/' + index + '/' + datatype\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    document = {\n",
    "        'size': limit,\n",
    "        'query': {\n",
    "            'knn': {\n",
    "                'embedding': {\n",
    "                    'vector': embedding,\n",
    "                    'k': limit\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # response\n",
    "    response = requests.get(url, auth=awsauth, json=document, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    output = ''\n",
    "    for item in data['hits']['hits']:\n",
    "        output += item['_source']['content'] + '\\n'\n",
    "    return output\n",
    "\n",
    "# main function\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")\n",
    "# this is the original prompt (query text)\n",
    "prompt = 'What does Albert Einstein do?'\n",
    "# convet the query text into embedding\n",
    "embedding = get_embedding(bedrock, prompt)\n",
    "# retrieve 5 most relevant entries from the knowledge base\n",
    "info = search(embedding, limit=5)\n",
    "# augment the prompt with the context\n",
    "# prompt = 'Use the context below to answer the question:\\n\\n=== Context ===\\n{0}\\n\\n=== Question ===\\n{1}'.format(info, prompt)\n",
    "# ask the foundation model\n",
    "modelId = 'ai21.j2-ultra'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "input = {'prompt': prompt, 'maxTokens': 200}\n",
    "body=json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept,contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "completions = response_body['completions']\n",
    "for part in completions:\n",
    "    print(part['data']['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae3348-ab14-47f4-910e-05322118a1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
